## Introduction

La Singularité technologique est un concept, selon lequel, à partir d'un point hypothétique de son évolution technologique, la civilisation humaine connaîtra une croissance technologique d'un ordre supérieur. Pour beaucoup, il est question d'intelligence artificielle quelle que soit la méthode pour la créer. Au-delà de ce point, le progrès ne serait plus l’œuvre que d’Intelligences artificielles, elles-mêmes en constante progression. Il induit des changements tels sur la société humaine que l’individu humain d’avant la Singularité ne peut ni les appréhender ni les prédire de manière fiable. Le risque étant la perte de pouvoir humain, politique, sur son destin.

Cet évènement est ainsi nommé par analogie avec l’impuissance de la physique moderne à proximité de la singularité gravitationnelle d'un trou noir, les forces en œuvre étant énormes bien que non infinies.



## La singularité vingienne
Le concept de Singularité technologique fut repopularisé en partie grâce au mathématicien et auteur Vernor Vinge. Vinge a commencé à parler de la singularité dans les années 1980 et a formulé ses idées dans son premier article sur le sujet en 1993 : l’essai Technological Singularity. Il y postule que, d’ici trente ans, l’humanité aurait les moyens de créer une intelligence surhumaine mettant un terme à l’ère humaine. Depuis, la singularité a été le sujet de nombreuses nouvelles et essais futuristes.

Vinge écrit que des intelligences surhumaines, créées par des humains aux capacités augmentées cybernétiquement ou par d'autres intelligences artificielles moins développées, seraient capables d’améliorer leurs propres capacités plus efficacement que les esprits humains les ayant conçues. Ainsi, une spirale de progrès de plus en plus rapide amènerait à des progrès technologiques très importants en une courte période de temps.

La Singularité peut être vue comme la fin des civilisations humaines actuelles et le début d’une nouvelle organisation. Dans son œuvre, Vinge s’interroge sur les raisons de cette fin et conclut que les humains pourraient s'organiser pendant la Singularité en une forme supérieure d’intelligence. Après la création de cette intelligence "surhumaine", les humains seraient, d’après Vinge, des formes de vie ayant une moindre influence sur le développement du monde, plutôt membres participants à un système que "pilotes dans l'avion".

## L'explosion de l'intelligence

Irving John Good a spéculé en 1965 sur les effets des machines plus intelligentes que les hommes:

Soit une machine ultraintelligente définie comme une machine qui peut largement dépasser toutes les activités intellectuelles d'un homme si habile soit-il. Comme la conception de machines est l'une de ces activités intellectuelles, une machine ultraintelligente pourrait concevoir des machines encore plus poussées : il y aurait alors incontestablement une « explosion de l'intelligence », et l'intelligence de l'homme serait laissée loin derrière. Ainsi, la première machine ultraintelligente sera la dernière invention que l'Homme doive jamais faire.

Jeff Hawkins a répondu à cette spéculation dans le rapport spécial IEEE Spectrum sur la singularité:

Le terme "Singularité", appliqué à des machines intelligentes se réfère à l'idée que lorsque des machines intelligentes peuvent concevoir des machines intelligentes, plus intelligentes qu'elles, cela provoquera une croissance exponentielle de l'intelligence des machines conduisant à une singularité de l'intelligence à l'infini (ou du moins immense). La croyance en cette idée se fonde sur une conception naïve de ce qu'est l'intelligence. Par analogie, imaginez que nous ayons un ordinateur qui pourrait concevoir de nouveaux ordinateurs (puces, systèmes et logiciels) plus rapides que lui-même. Est ce qu'un tel ordinateur produirait infiniment des ordinateurs ou même des ordinateurs plus rapides que ce que les humains pourraient construire d'eux-mêmes ? Non, cela pourrait accélérer le rythme des améliorations pour un certain temps, mais à la fin il y a des limites de taille et de vitesse. Nous arriverions au même endroit, nous aurions tout simplement été un peu plus rapide en prenant des risques. Et il n'y aurait eu aucune singularité.

## Loi de Moore

Selon la loi de Moore :

Le nombre de transistors de la dernière gamme de processeur est doublé tous les "deux ans", ce chiffre a baissé d'où l'accélération de l'accélération exponentielle. Et selon Ray Kurzweil, cela devrait se poursuivre jusqu'en 2019 pour cette technologie, jusqu'à ce qu'un autre type de technologie prenne le relais(optique, quantique ou moléculaire)[12].
Lawrence Krauss et Glenn D. Starkman annoncent quant à eux une limite ultime se trouvant dans 600 ans[13].
On remarque également :

- La puissance de calcul des superordinateurs est doublée tous les 10 mois.
La taille mémoire disponible sur un disque dur est doublée tous les 18 mois[14] : Un disque 3.5 : 2011 - 4 Tera octet - 2014 - 16 Tera Octet - Projection : 2023 - 1000 Tera Octet.

- La quantité d'information sur le réseau internet double tous les ~ 10 - 12 mois[15]
Le trafic internet double tous les 15 mois.

- Le niveau et la vitesse des interrelations sociales, ou web temps réel, suit également la loi de Moore. (Avec par exemple 350 000 tweets, et 1 000 000 de liens bit.ly, et 9 nouvelles page wikipedia, par minute, ...).

- Les caméras, télescopes, IRMs ( appareil principalement médical ) et séquenceurs ADN ont une précision et rapidité qui double tous les 18 mois.

- La consommation d'énergie suit également cette évolution[19], et l'énergie solaire spatiale est envisagé par des pays et entreprises. Le soleil produit plus d'énergie que nous n'en produirons durablement à la surface de la terre.

Il faut remarquer qu'il y a une limite physique dans la technologie utilisée actuellement, l'électronique ne peut aller sous la taille d'un atome, le nanomètre.

Cependant plusieurs voies permettraient de dépasser cette limite :

- Le changement de l'élément lié à l'information, exemple les processeurs ou de la mémoire quantique, moléculaire. Les avancées en ordinateurs moléculaires[22], et quantique[23] démontrent les possibilités réelles de ces technologies. La technologie quantique permettrait de résoudre des problèmes complexes avec un nombre d'opération comparativement énormément diminué (simplification np complexe). La technologie moléculaire permettrait l'apprentissage et la résolution d'autres types de problèmes complexes.

- Le changement d'architecture de processeur, les processeurs actuels ont une architecture parfaite pour les calculs, mais ne sont pas adaptés au problème complexe qui faciliterait la création d'une intelligence artificielle. Le DARPA a lancé un projet de construction de processeur probabiliste, le GP5, le cinquième type de processeur après les CPU, DSP, FPGA, et GPU. Les probabilités sont utilisées en intelligence artificielle pour le datamining, pour l'approche probabiliste dans certains domaines de l'intelligence artificielle ( reconnaissance visuelle, linguistique computationelle, sémantique, apprentissage machine et logique floue ).
Le changement de matériaux pour augmenter la fréquence (ex: gallium, gallium + sillicium)
Si la limite est atteinte, pour obtenir plus de puissance il faudra plus d'espace, les processeurs peuvent évoluer sur plusieurs couches (les 3 dimensions).
Les progrès logiciels à effectuer sont nombreux : structures de bases de données, utilisation...

## Critique des singularistes

### Critique du modèle scientifique: 
Des auteurs, sans critiquer directement la notion de Singularité, remettent en question l'idée d'accélération technologique.

Le concept de singularité ne tient pas compte des besoins et des ressources disponibles en énergie. Soit il postule des ressources infinies, soit il estime sans le démontrer que les besoins ne changeront que peu. Accessoirement, il ne tient pas compte de la limite quantique à laquelle la miniaturisation des composants électroniques se heurtera nécessairement un jour, ni de perturbations négligeables aux échelles actuelles et qui ne le resteront pas forcément à d'autres échelles (particules alpha, etc.).

Les hypothèses relatives à la Singularité sont régulièrement critiquées pour leur manque de solidité scientifique. Theodore Modis rappelle par exemple qu'une courbe exponentielle ne débouche sur aucune singularité, mais continue à croître à l'infini. Douglas Hofstadter se montre lui aussi très critique, craignant que cette idée n'exprime en fait qu'un vœu pieux.

Jonathan Huebner écrit en conclusion de son article que «  la preuve avancée indique que le rythme de l'innovation a atteint un pic il y a environ un siècle et est maintenant en déclin. Ce déclin est le plus probablement dû à une limite économique de la technologie ou à une limite du cerveau humain que nous approchons. Nous avons déjà parcouru 85% du chemin qui nous sépare de cette limite, et le rythme du développement technologique diminuera à chaque année écoulée. ». De telles analyses se retrouvent également chez Bob Seidensticker ou chez David Bodanis.

Il existe bien des limites politiques, économiques, militaires (et stratégiques), des limites en ressources, et surtout la connaissance et les découvertes technologiques ont également leurs limites. Comme le conçoit également Ray Kurzweil.

### Critique humaine
La connaissance, et le développement technologique ayant leurs limites : doit on remettre volontairement ou non notre pouvoir de décision en tant que race humaine à une intelligence artificielle : Intelligence qui par définition ne pourra être contrôlée de manière fiable.

C'est une question de choix politique à la fois à la grandeur d'un état et à la fois individuel : il n'y a pas une singularité, mais des singularités.

Cette réflexion mérite d'être commencée dès aujourd'hui dans toutes les sphères :

- Peut-on accepter toute évolution technologique, ayant un impact sur la définition de ce qu'est l'humanité ?

- Peut-on accepter une évolution technologique, ayant un trop grand risque de perte de contrôle de la société humaine ?

La connaissance, et le développement technologique ayant leurs limites, il est tout à fait possible de se passer d'une intelligence artificielle pour faire des découvertes afin d'atteindre ses limites, peut-être moins rapidement, ce n'est pas le temps qui manque à l'humanité. Et cela doit être un choix (politique) et un choix individuel, et non un choix économique.

### Critique dialectique
Plusieurs auteurs sont très critiques à l'endroit de la notion de singularité, notamment telle que développée par Ray Kurzweil. Theodore Modis écrit ainsi : « Ce que je veux dire est que Kurzweil et les singularistes sont impliqués dans une sorte de para-science, qui diffère des vraies sciences en termes de méthodologie et de rigueur. Ils ont tendance à négliger les pratiques scientifiques rigoureuses telles que se concentrer sur les lois naturelles, donner des définitions précises, vérifier les données méticuleusement, et estimer les incertitudes. [...] Kurzweil et les singularistes sont plus des croyants que des scientifiques. ». De son côté, Ted Gordon met également en doute les thèses de Kurzweil : « Kurzweil avance un argument frappant au sujet de l'accélération du changement. Il utilise de nombreuses courbes de croissance exponentielles, principalement concernant l'électronique, les nano-technologies et les ordinateurs, mais en incluant Internet et la biologie. Il montre une croissance similaire avec le PIB américain et le PIB par habitant. Il utilise également comme source majeure le travail de Modis sur le raccourcissement du temps entre les changements de paradigme. Il argumente en faveur de l'accélération du taux passé d'accélération et par conséquent de l'inévitabilité de la continuation de cet élan. Cependant, l'extrapolation sous toutes ses formes est dangereuse et condamnée en fin de compte à être fausse. ».

Drew McDermott, sans être aussi sévère, s'inquiète des conséquences de ce genre de littérature pour les recherches en Intelligence Articielle : « Bien que je ne pense pas que Kurzweil ait prouvé son affirmation à propos de l'IA (et je n'ai rien à dire à propos de ses arguments concernant la génétique, les nano-technologies, la politique ou l'écologie), il pourrait voir juste. Mais juste ou faux, j'aimerais qu'il arrête d'écrire de tels livres ! Le domaine de l'IA est régulièrement empesté de lubies qui semblent surgir à la moindre perturbation ».


Plus simplement, on peut se rappeler que les singularités prévues en histoire de la physique (effondrement de l'atome de Bohr, catastrophe de l'ultraviolet...) n'ont jamais été observées, mais ont conduit plus simplement à un changement de modèle à leur voisinage.

## Conclusion

LA singularité technologique est, certe, un sujet qui préoccupe nombreux futuristes, et mérite une discussion dans lemilieu de la recherche. Mais étant donné son rapprochement de la science fiction et l'éloignement des bases de discussion scientifique, c'est un sujet qui dirige nos yeux sur une sujet important relatif à l'IA qui est l'éthique, le financement et l'avancée des projets IA.

Comment maintenir l’économie mondiale active pendant encore au moins dix ans ? Qui est prêt à financer un projet d’IA ? Qui devons-nous recruter pour un projet d’IA ? Comment pouvons-nous éviter les réactions hostiles anti-technologie habituelles ? Et que faisons-nous si la nanotech arrive en premier ?

Telles sont les questions pratiques auxquelles nous ferons face dans l’avenir immédiat.
