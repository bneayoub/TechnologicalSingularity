## Introduction

La Singularité technologique est un concept, selon lequel, à partir d'un point hypothétique de son évolution technologique, la civilisation humaine connaîtra une croissance technologique d'un ordre supérieur. Pour beaucoup, il est question d'intelligence artificielle quelle que soit la méthode pour la créer. Au-delà de ce point, le progrès ne serait plus l’œuvre que d’Intelligences artificielles, elles-mêmes en constante progression. Il induit des changements tels sur la société humaine que l’individu humain d’avant la Singularité ne peut ni les appréhender ni les prédire de manière fiable. Le risque étant la perte de pouvoir humain, politique, sur son destin.

Cet évènement est ainsi nommé par analogie avec l’impuissance de la physique moderne à proximité de la singularité gravitationnelle d'un trou noir, les forces en œuvre étant énormes bien que non infinies.



## La singularité vingienne
Le concept de Singularité technologique fut repopularisé en partie grâce au mathématicien et auteur Vernor Vinge. Vinge a commencé à parler de la singularité dans les années 1980 et a formulé ses idées dans son premier article sur le sujet en 1993 : l’essai Technological Singularity. Il y postule que, d’ici trente ans, l’humanité aurait les moyens de créer une intelligence surhumaine mettant un terme à l’ère humaine. Depuis, la singularité a été le sujet de nombreuses nouvelles et essais futuristes.

Vinge écrit que des intelligences surhumaines, créées par des humains aux capacités augmentées cybernétiquement ou par d'autres intelligences artificielles moins développées, seraient capables d’améliorer leurs propres capacités plus efficacement que les esprits humains les ayant conçues. Ainsi, une spirale de progrès de plus en plus rapide amènerait à des progrès technologiques très importants en une courte période de temps.

La Singularité peut être vue comme la fin des civilisations humaines actuelles et le début d’une nouvelle organisation. Dans son œuvre, Vinge s’interroge sur les raisons de cette fin et conclut que les humains pourraient s'organiser pendant la Singularité en une forme supérieure d’intelligence. Après la création de cette intelligence "surhumaine", les humains seraient, d’après Vinge, des formes de vie ayant une moindre influence sur le développement du monde, plutôt membres participants à un système que "pilotes dans l'avion".

## L'explosion de l'intelligence

Irving John Good a spéculé en 1965 sur les effets des machines plus intelligentes que les hommes:

Soit une machine ultraintelligente définie comme une machine qui peut largement dépasser toutes les activités intellectuelles d'un homme si habile soit-il. Comme la conception de machines est l'une de ces activités intellectuelles, une machine ultraintelligente pourrait concevoir des machines encore plus poussées : il y aurait alors incontestablement une « explosion de l'intelligence », et l'intelligence de l'homme serait laissée loin derrière. Ainsi, la première machine ultraintelligente sera la dernière invention que l'Homme doive jamais faire.

Jeff Hawkins a répondu à cette spéculation dans le rapport spécial IEEE Spectrum sur la singularité:

Le terme "Singularité", appliqué à des machines intelligentes se réfère à l'idée que lorsque des machines intelligentes peuvent concevoir des machines intelligentes, plus intelligentes qu'elles, cela provoquera une croissance exponentielle de l'intelligence des machines conduisant à une singularité de l'intelligence à l'infini (ou du moins immense). La croyance en cette idée se fonde sur une conception naïve de ce qu'est l'intelligence. Par analogie, imaginez que nous ayons un ordinateur qui pourrait concevoir de nouveaux ordinateurs (puces, systèmes et logiciels) plus rapides que lui-même. Est ce qu'un tel ordinateur produirait infiniment des ordinateurs ou même des ordinateurs plus rapides que ce que les humains pourraient construire d'eux-mêmes ? Non, cela pourrait accélérer le rythme des améliorations pour un certain temps, mais à la fin il y a des limites de taille et de vitesse. Nous arriverions au même endroit, nous aurions tout simplement été un peu plus rapide en prenant des risques. Et il n'y aurait eu aucune singularité.

## Loi de Moore

Selon la loi de Moore :

Le nombre de transistors de la dernière gamme de processeur est doublé tous les "deux ans", ce chiffre a baissé d'où l'accélération de l'accélération exponentielle. Et selon Ray Kurzweil, cela devrait se poursuivre jusqu'en 2019 pour cette technologie, jusqu'à ce qu'un autre type de technologie prenne le relais(optique, quantique ou moléculaire)[12].
Lawrence Krauss et Glenn D. Starkman annoncent quant à eux une limite ultime se trouvant dans 600 ans[13].
On remarque également :

- La puissance de calcul des superordinateurs est doublée tous les 10 mois.
La taille mémoire disponible sur un disque dur est doublée tous les 18 mois[14] : Un disque 3.5 : 2011 - 4 Tera octet - 2014 - 16 Tera Octet - Projection : 2023 - 1000 Tera Octet.

- La quantité d'information sur le réseau internet double tous les ~ 10 - 12 mois[15]
Le trafic internet double tous les 15 mois.

- Le niveau et la vitesse des interrelations sociales, ou web temps réel, suit également la loi de Moore. (Avec par exemple 350 000 tweets, et 1 000 000 de liens bit.ly, et 9 nouvelles page wikipedia, par minute, ...).

- Les caméras, télescopes, IRMs ( appareil principalement médical ) et séquenceurs ADN ont une précision et rapidité qui double tous les 18 mois.

- La consommation d'énergie suit également cette évolution[19], et l'énergie solaire spatiale est envisagé par des pays et entreprises. Le soleil produit plus d'énergie que nous n'en produirons durablement à la surface de la terre.

Il faut remarquer qu'il y a une limite physique dans la technologie utilisée actuellement, l'électronique ne peut aller sous la taille d'un atome, le nanomètre.

Cependant plusieurs voies permettraient de dépasser cette limite :

- Le changement de l'élément lié à l'information, exemple les processeurs ou de la mémoire quantique, moléculaire. Les avancées en ordinateurs moléculaires[22], et quantique[23] démontrent les possibilités réelles de ces technologies. La technologie quantique permettrait de résoudre des problèmes complexes avec un nombre d'opération comparativement énormément diminué (simplification np complexe). La technologie moléculaire permettrait l'apprentissage et la résolution d'autres types de problèmes complexes.

- Le changement d'architecture de processeur, les processeurs actuels ont une architecture parfaite pour les calculs, mais ne sont pas adaptés au problème complexe qui faciliterait la création d'une intelligence artificielle. Le DARPA a lancé un projet de construction de processeur probabiliste, le GP5, le cinquième type de processeur après les CPU, DSP, FPGA, et GPU. Les probabilités sont utilisées en intelligence artificielle pour le datamining, pour l'approche probabiliste dans certains domaines de l'intelligence artificielle ( reconnaissance visuelle, linguistique computationelle, sémantique, apprentissage machine et logique floue ).
Le changement de matériaux pour augmenter la fréquence (ex: gallium, gallium + sillicium)
Si la limite est atteinte, pour obtenir plus de puissance il faudra plus d'espace, les processeurs peuvent évoluer sur plusieurs couches (les 3 dimensions).
Les progrès logiciels à effectuer sont nombreux : structures de bases de données, utilisation...

## Critique des singularistes

### Critique du modèle scientifique: 
Des auteurs, sans critiquer directement la notion de Singularité, remettent en question l'idée d'accélération technologique.

Le concept de singularité ne tient pas compte des besoins et des ressources disponibles en énergie. Soit il postule des ressources infinies, soit il estime sans le démontrer que les besoins ne changeront que peu. Accessoirement, il ne tient pas compte de la limite quantique à laquelle la miniaturisation des composants électroniques se heurtera nécessairement un jour, ni de perturbations négligeables aux échelles actuelles et qui ne le resteront pas forcément à d'autres échelles (particules alpha, etc.).

Les hypothèses relatives à la Singularité sont régulièrement critiquées pour leur manque de solidité scientifique. Theodore Modis rappelle par exemple qu'une courbe exponentielle ne débouche sur aucune singularité, mais continue à croître à l'infini. Douglas Hofstadter se montre lui aussi très critique, craignant que cette idée n'exprime en fait qu'un vœu pieux.

Jonathan Huebner écrit en conclusion de son article que «  la preuve avancée indique que le rythme de l'innovation a atteint un pic il y a environ un siècle et est maintenant en déclin. Ce déclin est le plus probablement dû à une limite économique de la technologie ou à une limite du cerveau humain que nous approchons. Nous avons déjà parcouru 85% du chemin qui nous sépare de cette limite, et le rythme du développement technologique diminuera à chaque année écoulée. ». De telles analyses se retrouvent également chez Bob Seidensticker ou chez David Bodanis.

Il existe bien des limites politiques, économiques, militaires (et stratégiques), des limites en ressources, et surtout la connaissance et les découvertes technologiques ont également leurs limites. Comme le conçoit également Ray Kurzweil.
